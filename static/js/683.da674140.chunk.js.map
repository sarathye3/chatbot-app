{"version":3,"file":"static/js/683.da674140.chunk.js","mappings":"6KAIA,IAAIA,EAAoB,IAAIC,IACxBC,EAAuB,EAG3B,MAAMC,EAAqB,CACzB,gBAAiB,CACfC,MAAO,YACPC,UAAW,SACXC,UAAW,YAEb,QAAS,CACPF,MAAO,WACPC,UAAW,OACXC,UAAW,QAEb,cAAe,CACbF,MAAO,WACPC,UAAW,cACXC,UAAW,QAEb,iBAAkB,CAChBF,MAAO,UACPC,UAAW,QACXC,UAAW,YAEb,kBAAmB,CACjBF,MAAO,WACPC,UAAW,SACXC,UAAW,QAEb,gBAAiB,CACfF,MAAO,gBACPC,UAAW,OACXC,UAAW,cAKTC,EAAgB,CACpB,6JACA,8JACA,wHACA,4MACA,0LACA,wMACA,yLACA,6LACA,sLACA,0NACA,oPACA,6NACA,8NACA,8MACA,wOACA,4OACA,oOACA,6PACA,yRACA,8NAIIC,EACM,CACR,wDACA,4DACA,wDAJEA,EAME,CACJ,mGACA,mFACA,kGATEA,EAWI,CACN,8CACA,mEACA,8DAdEA,EAgBK,CACP,2CACA,6CACA,2CAKEC,EAASC,GAAO,IAAIC,QAAQC,GAAWC,WAAWD,EAASF,IAE3DI,EAAsBC,GACnBA,EAAMC,KAAKC,MAAMD,KAAKE,SAAWH,EAAMI,SAG1CC,EAAwB,SAACC,GAA4B,IAAnBC,EAAQC,UAAAJ,OAAA,QAAAK,IAAAD,UAAA,GAAAA,UAAA,GAAG,CAAC,EAClD,MAAME,EAAeJ,EAAQK,cAG7B,IAAIC,EAcJ,OAZEA,EADEF,EAAaG,SAAS,UAAYH,EAAaG,SAAS,OAASH,EAAaG,SAAS,OAC1Ed,EAAmBN,GACzBiB,EAAaG,SAAS,SAAWH,EAAaG,SAAS,UACjDd,EAAmBN,GACzBiB,EAAaG,SAAS,UAAYH,EAAaG,SAAS,UAClDd,EAAmBN,GACzBiB,EAAaG,SAAS,QAAUH,EAAaG,SAAS,YAAcH,EAAaG,SAAS,WACpFd,EAAmBN,GAEnBM,EAAmBP,GAI7BsB,EAAwBF,EAAcL,EAC/C,EAEMO,EAA0BA,CAACC,EAAUC,KACzC,IAAKA,EAAQ,OAAOD,EAEpB,MAAM,MAAEE,EAAK,YAAEC,EAAW,kBAAEC,EAAiB,aAAEC,GAAiBJ,EAGhE,GAAIC,GAAS7B,EAAmB6B,GAAQ,CACtC,MAAMI,EAAajC,EAAmB6B,GAGT,UAAzBI,EAAW/B,WAAyByB,EAASX,OAAS,IACxDW,EAAWA,EAASO,UAAU,EAAG,KAAO,MACN,SAAzBD,EAAW/B,WAAwByB,EAASX,OAAS,MAC9DW,GAAY,gHAIW,YAArBM,EAAWhC,MACb0B,EAAWA,EAASQ,QAAQ,QAAS,MAAMA,QAAQ,QAAS,MAAMA,QAAQ,OAAQ,MACpD,kBAArBF,EAAWhC,QACpB0B,GAAY,4EAEhB,CAGA,QAAoBN,IAAhBS,EACF,GAAIA,EAAc,GAEhBH,EAAWA,EAASQ,QAAQ,MAAO,KAAKA,QAAQ,QAAS,SACpD,GAAIL,EAAc,IAAK,CAQ5BH,GAAYhB,EANc,CACxB,gBACA,UACA,6CACA,6DAGJ,CAIF,GAAIoB,EACF,OAAQA,GACN,IAAK,WACHJ,EAAW,gBAAQA,EAAW,0BAA4BhB,EAAmB,CAC3E,gDACA,gDACA,wDACG,IACL,MACF,IAAK,aACHgB,EAAWA,EAASQ,QAAQ,UAAW,2CACzBV,SAAS,SACrBE,GAAY,yGAEd,MACF,IAAK,WACHA,EAAW,gBAAQA,EAASQ,QAAQ,MAAO,MAC3CR,GAAY,yEACZ,MACF,IAAK,UACHA,EAAWA,EAASS,MAAM,QAAQ,GAAGD,QAAQ,QAAS,IAAIA,QAAQ,SAAU,IAC5E,MACF,IAAK,cACHR,GAAY,+MAUlB,OAJIK,GAAgBA,EAAaP,SAAS,UACxCE,GAAY,6FAGPA,GAGHU,EAAgB,SAACC,GAAgD,IAA3BC,EAAcnB,UAAAJ,OAAA,QAAAK,IAAAD,UAAA,GAAAA,UAAA,GAAG,KAC3D,MAAO,CACLoB,GAAIzC,IACJuC,OACAG,MAJ8BrB,UAAAJ,OAAA,QAAAK,IAAAD,UAAA,IAAAA,UAAA,GAK9BsB,WAAW,IAAIC,MAAOC,cACtBL,iBAEJ,EAIaM,EAAiB,CAE5BC,YAAiBC,gBACTzC,EAAM,KACL,CACL0C,SAAS,EACTC,KAAM,CAAEC,OAAQ,KAAMhC,QAAS,oCAKnC,sBAAMiC,SACE7C,EAAM,KAWZ,MAAO,CACL0C,SAAS,EACTC,KAXwBG,MAAMC,KAAKxD,EAAkByD,WAAWC,IAAIC,IAAA,IAAEhB,EAAIiB,GAAKD,EAAA,MAAM,CACrFhB,KACAkB,MAAOD,EAAKC,MACZC,YAAaF,EAAKG,SAASH,EAAKG,SAAS5C,OAAS,GAClD6C,aAAcJ,EAAKG,SAAS5C,OAC5B8C,UAAWL,EAAKK,UAChBC,UAAWN,EAAKM,aAKQC,KAAK,CAACC,EAAGC,IAAM,IAAIvB,KAAKuB,EAAEH,WAAa,IAAIpB,KAAKsB,EAAEF,YAE9E,EAGA,wBAAMI,SACE7D,EAAM,KAEZ,MAAMiC,EAAiB,aAAaI,KAAKyB,SAASvD,KAAKE,SAASsD,SAAS,IAAIC,OAAO,EAAG,KACjFF,GAAM,IAAIzB,MAAOC,cAQjB2B,EAAe,CACnB/B,GAAID,EACJmB,MAAO,WACPE,SAAU,CATWvB,EACrB,2DACA,EACAE,IAOAuB,UAAWM,EACXL,UAAWK,GAKb,OAFAvE,EAAkB2E,IAAIjC,EAAgBgC,GAE/B,CACLvB,SAAS,EACTC,KAAMsB,EAEV,EAGA,qBAAME,CAAgBlC,SACdjC,EAAM,KAEZ,MAAMiE,EAAe1E,EAAkB6E,IAAInC,GAE3C,IAAKgC,EACH,MAAM,IAAII,MAAM,0BAGlB,MAAO,CACL3B,SAAS,EACTC,KAAMsB,EAEV,EAGA,iBAAMK,CAAYrC,EAAgBrB,GAAyB,IAAhBC,EAAQC,UAAAJ,OAAA,QAAAK,IAAAD,UAAA,GAAAA,UAAA,GAAG,CAAC,EACrD,IAAKF,GAA8B,kBAAZA,IAAyBA,EAAQ2D,OACtD,MAAM,IAAIF,MAAM,sDAGlB,IAAIJ,EAAe1E,EAAkB6E,IAAInC,GAGzC,IAAKgC,EAAc,CACjB,MAAMH,GAAM,IAAIzB,MAAOC,cACvB2B,EAAe,CACb/B,GAAID,EACJmB,MAAOxC,EAAQF,OAAS,GAAKE,EAAQgB,UAAU,EAAG,IAAM,MAAQhB,EAChE0C,SAAU,GACVE,UAAWM,EACXL,UAAWK,GAEbvE,EAAkB2E,IAAIjC,EAAgBgC,EACxC,CAGA,MAAMO,EAAczC,EAAcnB,EAAQ2D,QAAQ,EAAOtC,GACzDgC,EAAaX,SAASmB,KAAKD,GAGgC,IAAvDP,EAAaX,SAASoB,OAAOC,IAAMA,EAAExC,OAAOzB,SAC9CuD,EAAab,MAAQxC,EAAQF,OAAS,GAAKE,EAAQgB,UAAU,EAAG,IAAM,MAAQhB,GAKhF,IAAIgE,EAEJ,GAHoB/D,GAAYA,EAASgE,iBAGxB,CAGfD,EAAY7C,EAAc,IAAI,EAAME,GACpCgC,EAAaX,SAASmB,KAAKG,SAGrB5E,EAAM,KAGZ,MAAM8E,EAAenE,EAAsBC,EAASC,GAGpD+D,EAAU5C,KAAO8C,EACjBF,EAAUG,aAAc,CAC1B,KAAO,CAEL,MAAMC,EAAiC,IAAhBzE,KAAKE,SAAkB,UACxCT,EAAMgF,GAGZ,MAAMC,EAAiBtE,EAAsBC,EAASC,GACtD+D,EAAY7C,EAAckD,GAAgB,EAAMhD,GAChDgC,EAAaX,SAASmB,KAAKG,EAC7B,CAKA,OAFAX,EAAaR,WAAY,IAAIpB,MAAOC,cAE7B,CACLI,SAAS,EACTC,KAAM,CACJ6B,cACAI,YACAX,aAAc,CACZ/B,GAAI+B,EAAa/B,GACjBkB,MAAOa,EAAab,MACpBG,aAAcU,EAAaX,SAAS5C,SAI5C,EAGA,wBAAMwE,CAAmBjD,SACjBjC,EAAM,KAIZ,IAFgBT,EAAkB4F,OAAOlD,GAGvC,MAAM,IAAIoC,MAAM,0BAGlB,MAAO,CACL3B,SAAS,EACT9B,QAAS,oCAEb,EAGA4B,sBAA2B4C,gBACnBpF,EAAM,KAEZT,EAAkB8F,QAClB5F,EAAuB,EAEhB,CACLiD,SAAS,EACT9B,QAAS,+BAMF0D,EAAc9B,MAAO5B,EAASC,WACnCb,EAAsB,IAAhBO,KAAKE,SAAkB,KAC5BE,EAAsBC,EAASC,IAGxC,G","sources":["services/mockApi.js"],"sourcesContent":["// Mock API that simulates real backend endpoints\n// This is used as a fallback when actual API endpoints are unavailable\n\n// In-memory storage for conversations (simulates database)\nlet mockConversations = new Map();\nlet mockMessageIdCounter = 1;\n\n// Model-specific response variations\nconst modelPersonalities = {\n  'gpt-3.5-turbo': {\n    style: 'efficient',\n    avgLength: 'medium',\n    technical: 'moderate'\n  },\n  'gpt-4': {\n    style: 'thorough',\n    avgLength: 'long',\n    technical: 'high'\n  },\n  'gpt-4-turbo': {\n    style: 'balanced',\n    avgLength: 'medium-long',\n    technical: 'high'\n  },\n  'claude-3-haiku': {\n    style: 'concise',\n    avgLength: 'short',\n    technical: 'moderate'\n  },\n  'claude-3-sonnet': {\n    style: 'balanced',\n    avgLength: 'medium',\n    technical: 'high'\n  },\n  'claude-3-opus': {\n    style: 'comprehensive',\n    avgLength: 'long',\n    technical: 'very-high'\n  }\n};\n\n// Mock responses database with markdown formatting\nconst mockResponses = [\n  \"That's an **interesting question**! Let me think about that for a moment.\\n\\nHere are my thoughts:\\n- First consideration\\n- Second point\\n- Final insight\",\n  \"I understand what you're asking. Here's what I think about that topic:\\n\\n```javascript\\nconst answer = 'This could be helpful';\\nconsole.log(answer);\\n```\",\n  \"Great point! I'd be happy to help you with that.\\n\\n> This is an important topic that deserves careful consideration.\",\n  \"That's a thoughtful question. From my perspective, I would say:\\n\\n## Key Points\\n\\n1. **First aspect** - detailed explanation\\n2. **Second aspect** - more context\\n3. **Conclusion** - summary thoughts\",\n  \"I see where you're coming from. Let me provide some insights:\\n\\n- ✅ This approach works well\\n- ⚠️ Consider this limitation\\n- 💡 Here's a better alternative\",\n  \"Thanks for sharing that with me. Here's my take:\\n\\n### Analysis\\n\\nThe situation you've described is quite common. Many people face similar challenges, and there are several ways to approach this.\",\n  \"That's definitely something worth exploring. Let me break it down:\\n\\n```python\\ndef solve_problem():\\n    return \\\"Step by step solution\\\"\\n```\\n\\nThis code demonstrates the concept.\",\n  \"I appreciate you bringing this up. Based on what you've told me:\\n\\n> \\\"The best solutions often come from understanding the problem deeply first.\\\"\\n\\nLet me elaborate on this principle.\",\n  \"That's a complex topic, but I'll do my best to explain it clearly:\\n\\n## Overview\\n\\n**Key concepts:**\\n- Fundamental principle\\n- Practical application\\n- Real-world implications\",\n  \"Interesting! I have some thoughts that might be helpful:\\n\\n1. Consider this perspective\\n2. Think about these factors\\n3. Here's what I recommend\\n\\nLet me know if you'd like me to elaborate on any of these points!\",\n  \"I can definitely help you with that. Let me walk you through it **step by step**:\\n\\n### Step 1: Preparation\\nFirst, you'll need to...\\n\\n### Step 2: Implementation\\nNext, proceed with...\\n\\n### Step 3: Verification\\nFinally, confirm that...\",\n  \"That's a great question that many people wonder about. Here's what I know:\\n\\n```markdown\\n# Important Information\\n\\n- Fact 1: Detailed explanation\\n- Fact 2: Supporting evidence\\n- Fact 3: Practical implications\\n```\",\n  \"I'm glad you asked! This is actually one of my **favorite topics** to discuss.\\n\\n[Learn more about this topic](https://example.com)\\n\\nThe fascinating thing about this subject is how it connects to so many other areas.\",\n  \"That's something I've been thinking about lately too. Here's my perspective:\\n\\n> The key insight is that *simplicity* often leads to the most elegant solutions.\\n\\nWhat do you think about this approach?\",\n  \"Thanks for the question! I think there are several ways to approach this:\\n\\n| Approach | Pros | Cons |\\n|----------|------|------|\\n| Method A | Fast | Limited |\\n| Method B | Flexible | Complex |\\n| Method C | Simple | Slower |\",\n  \"You've raised an **excellent point**. Let me explain how I see it:\\n\\n### The Big Picture\\n\\nThis connects to broader themes in the field. Consider how this relates to:\\n\\n- Historical context\\n- Current trends\\n- Future implications\",\n  \"That's a really good observation. Here's what I would add:\\n\\n```typescript\\ninterface Solution {\\n  approach: string;\\n  benefits: string[];\\n  considerations: string[];\\n}\\n```\\n\\nThis structure helps organize our thinking.\",\n  \"I appreciate your curiosity about this topic. Let me share some insights:\\n\\n## Core Principles\\n\\n1. **Understanding** comes first\\n2. **Practice** reinforces learning\\n3. **Application** demonstrates mastery\\n\\nEach step builds on the previous one.\",\n  \"That's exactly the kind of question I love to explore. Here's my thoughts:\\n\\n### Quick Answer\\n*Yes, this is definitely possible.*\\n\\n### Detailed Explanation\\nThe reason this works is because...\\n\\n### Next Steps\\n- Try this approach\\n- Monitor the results\\n- Adjust as needed\",\n  \"You're absolutely right to wonder about that. Let me clarify:\\n\\n> \\\"Clarity comes from asking the right questions, not just finding quick answers.\\\"\\n\\nThis principle applies perfectly to your situation. Here's how...\"\n];\n\n// Context-aware responses based on keywords\nconst contextualResponses = {\n  greeting: [\n    \"Hello! Great to meet you. How can I assist you today?\",\n    \"Hi there! I'm excited to help you with whatever you need.\",\n    \"Hey! Thanks for reaching out. What can I do for you?\"\n  ],\n  help: [\n    \"I'm here to help! I can assist with questions, provide information, or just have a conversation.\",\n    \"Of course! I'd be happy to help you with whatever you need. What's on your mind?\",\n    \"I'm designed to be helpful across a wide range of topics. What would you like assistance with?\"\n  ],\n  thanks: [\n    \"You're very welcome! I'm glad I could help.\",\n    \"Happy to help! Feel free to ask if you have any other questions.\",\n    \"My pleasure! Is there anything else I can assist you with?\"\n  ],\n  goodbye: [\n    \"Goodbye! It was great chatting with you.\",\n    \"Take care! Feel free to come back anytime.\",\n    \"See you later! Hope to chat again soon.\"\n  ]\n};\n\n// Utility functions\nconst delay = (ms) => new Promise(resolve => setTimeout(resolve, ms));\n\nconst getRandomFromArray = (array) => {\n  return array[Math.floor(Math.random() * array.length)];\n};\n\nconst getContextualResponse = (message, aiConfig = {}) => {\n  const lowerMessage = message.toLowerCase();\n  \n  // Get base response\n  let baseResponse;\n  if (lowerMessage.includes('hello') || lowerMessage.includes('hi') || lowerMessage.includes('hey')) {\n    baseResponse = getRandomFromArray(contextualResponses.greeting);\n  } else if (lowerMessage.includes('help') || lowerMessage.includes('assist')) {\n    baseResponse = getRandomFromArray(contextualResponses.help);\n  } else if (lowerMessage.includes('thank') || lowerMessage.includes('thanks')) {\n    baseResponse = getRandomFromArray(contextualResponses.thanks);\n  } else if (lowerMessage.includes('bye') || lowerMessage.includes('goodbye') || lowerMessage.includes('see you')) {\n    baseResponse = getRandomFromArray(contextualResponses.goodbye);\n  } else {\n    baseResponse = getRandomFromArray(mockResponses);\n  }\n  \n  // Apply AI configuration modifications\n  return applyAIConfigToResponse(baseResponse, aiConfig);\n};\n\nconst applyAIConfigToResponse = (response, config) => {\n  if (!config) return response;\n  \n  const { model, temperature, personalityPreset, systemPrompt } = config;\n  \n  // Apply model-specific characteristics\n  if (model && modelPersonalities[model]) {\n    const modelProps = modelPersonalities[model];\n    \n    // Adjust response length based on model\n    if (modelProps.avgLength === 'short' && response.length > 200) {\n      response = response.substring(0, 150) + '...';\n    } else if (modelProps.avgLength === 'long' && response.length < 300) {\n      response += '\\n\\nAdditionally, this topic connects to several interesting concepts that might be worth exploring further.';\n    }\n    \n    // Add model-specific style markers\n    if (modelProps.style === 'concise') {\n      response = response.replace(/\\n\\n/g, '\\n').replace(/### /g, '**').replace(/## /g, '**');\n    } else if (modelProps.style === 'comprehensive') {\n      response += '\\n\\n*Note: This analysis considers multiple perspectives and edge cases.*';\n    }\n  }\n  \n  // Apply temperature-based randomness\n  if (temperature !== undefined) {\n    if (temperature < 0.3) {\n      // Low temperature: more focused and consistent\n      response = response.replace(/!+/g, '.').replace(/\\*\\*/g, '');\n    } else if (temperature > 1.2) {\n      // High temperature: more creative and varied\n      const creativeAdditions = [\n        ' 🚀',\n        ' ✨',\n        '\\n\\n*Interesting perspective to consider!*',\n        '\\n\\n💭 *What do you think about this approach?*'\n      ];\n      response += getRandomFromArray(creativeAdditions);\n    }\n  }\n  \n  // Apply personality-specific modifications\n  if (personalityPreset) {\n    switch (personalityPreset) {\n      case 'creative':\n        response = '🎨 ' + response + '\\n\\n*Creative insight: ' + getRandomFromArray([\n          'This sparks so many innovative possibilities!',\n          'I love exploring unique angles on this topic.',\n          'There are countless creative ways to approach this.'\n        ]) + '*';\n        break;\n      case 'technical':\n        response = response.replace(/\\.\\.\\./g, ' with specific implementation details.');\n        if (!response.includes('```')) {\n          response += '\\n\\n```\\n// Technical implementation notes\\n// Consider: error handling, edge cases, performance\\n```';\n        }\n        break;\n      case 'friendly':\n        response = '😊 ' + response.replace(/\\./g, '! ');\n        response += '\\n\\nI hope this helps! Feel free to ask me anything else. 🌟';\n        break;\n      case 'concise':\n        response = response.split('\\n\\n')[0].replace(/\\*\\*/g, '').replace(/###? /g, '');\n        break;\n      case 'educational':\n        response += '\\n\\n**Learning objective:** Understanding this concept will help you build foundational knowledge for more advanced topics.\\n\\n📚 *Would you like me to explain any specific part in more detail?*';\n        break;\n    }\n  }\n  \n  // Apply custom system prompt influence\n  if (systemPrompt && systemPrompt.includes('code')) {\n    response += '\\n\\n```\\n// Example implementation\\nconsole.log(\"Example code based on discussion\");\\n```';\n  }\n  \n  return response;\n};\n\nconst createMessage = (text, isBot = false, conversationId = null) => {\n  return {\n    id: mockMessageIdCounter++,\n    text,\n    isBot,\n    timestamp: new Date().toISOString(),\n    conversationId\n  };\n};\n\n// Mock API Functions (simulating real endpoints)\n\nexport const mockApiService = {\n  // Simulate health check\n  async checkHealth() {\n    await delay(100); // Simulate network delay\n    return {\n      success: true,\n      data: { status: 'OK', message: 'Mock AI Chatbot API is running' }\n    };\n  },\n\n  // Simulate getting all conversations\n  async getConversations() {\n    await delay(200);\n    \n    const conversationsList = Array.from(mockConversations.entries()).map(([id, conv]) => ({\n      id,\n      title: conv.title,\n      lastMessage: conv.messages[conv.messages.length - 1],\n      messageCount: conv.messages.length,\n      createdAt: conv.createdAt,\n      updatedAt: conv.updatedAt\n    }));\n    \n    return {\n      success: true,\n      data: conversationsList.sort((a, b) => new Date(b.updatedAt) - new Date(a.updatedAt))\n    };\n  },\n\n  // Simulate creating new conversation\n  async createConversation() {\n    await delay(300);\n    \n    const conversationId = `mock_conv_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n    const now = new Date().toISOString();\n    \n    const welcomeMessage = createMessage(\n      \"Hello! I'm your AI assistant. How can I help you today?\",\n      true,\n      conversationId\n    );\n    \n    const conversation = {\n      id: conversationId,\n      title: 'New Chat',\n      messages: [welcomeMessage],\n      createdAt: now,\n      updatedAt: now\n    };\n    \n    mockConversations.set(conversationId, conversation);\n    \n    return {\n      success: true,\n      data: conversation\n    };\n  },\n\n  // Simulate getting specific conversation\n  async getConversation(conversationId) {\n    await delay(150);\n    \n    const conversation = mockConversations.get(conversationId);\n    \n    if (!conversation) {\n      throw new Error('Conversation not found');\n    }\n    \n    return {\n      success: true,\n      data: conversation\n    };\n  },\n\n  // Simulate sending message to conversation\n  async sendMessage(conversationId, message, aiConfig = {}) {\n    if (!message || typeof message !== 'string' || !message.trim()) {\n      throw new Error('Message is required and must be a non-empty string');\n    }\n    \n    let conversation = mockConversations.get(conversationId);\n    \n    // Create conversation if it doesn't exist\n    if (!conversation) {\n      const now = new Date().toISOString();\n      conversation = {\n        id: conversationId,\n        title: message.length > 50 ? message.substring(0, 50) + '...' : message,\n        messages: [],\n        createdAt: now,\n        updatedAt: now\n      };\n      mockConversations.set(conversationId, conversation);\n    }\n    \n    // Add user message\n    const userMessage = createMessage(message.trim(), false, conversationId);\n    conversation.messages.push(userMessage);\n    \n    // Update conversation title if it's the first user message\n    if (conversation.messages.filter(m => !m.isBot).length === 1) {\n      conversation.title = message.length > 50 ? message.substring(0, 50) + '...' : message;\n    }\n    \n    // Check if streaming is enabled\n    const isStreaming = aiConfig && aiConfig.streamingEnabled;\n    let aiMessage;\n    \n    if (isStreaming) {\n      // For streaming, create initial message and return it\n      // The actual streaming would be handled differently in real implementation\n      aiMessage = createMessage('', true, conversationId);\n      conversation.messages.push(aiMessage);\n      \n      // Simulate initial delay\n      await delay(500);\n      \n      // Generate full response\n      const fullResponse = getContextualResponse(message, aiConfig);\n      \n      // Update the message with full response\n      aiMessage.text = fullResponse;\n      aiMessage.isStreaming = false;\n    } else {\n      // Simulate AI processing delay\n      const processingTime = Math.random() * 2000 + 1000; // 1-3 seconds\n      await delay(processingTime);\n      \n      // Generate AI response based on configuration\n      const aiResponseText = getContextualResponse(message, aiConfig);\n      aiMessage = createMessage(aiResponseText, true, conversationId);\n      conversation.messages.push(aiMessage);\n    }\n    \n    // Update conversation timestamp\n    conversation.updatedAt = new Date().toISOString();\n    \n    return {\n      success: true,\n      data: {\n        userMessage,\n        aiMessage,\n        conversation: {\n          id: conversation.id,\n          title: conversation.title,\n          messageCount: conversation.messages.length\n        }\n      }\n    };\n  },\n\n  // Simulate deleting conversation\n  async deleteConversation(conversationId) {\n    await delay(200);\n    \n    const deleted = mockConversations.delete(conversationId);\n    \n    if (!deleted) {\n      throw new Error('Conversation not found');\n    }\n    \n    return {\n      success: true,\n      message: 'Conversation deleted successfully'\n    };\n  },\n\n  // Simulate clearing all conversations\n  async clearAllConversations() {\n    await delay(250);\n    \n    mockConversations.clear();\n    mockMessageIdCounter = 1;\n    \n    return {\n      success: true,\n      message: 'All conversations cleared'\n    };\n  }\n};\n\n// Legacy function for backward compatibility (if needed)\nexport const sendMessage = async (message, aiConfig) => {\n  await delay(Math.random() * 1000 + 1000); // 1-2 seconds\n  return getContextualResponse(message, aiConfig);\n};\n\nexport default mockApiService;"],"names":["mockConversations","Map","mockMessageIdCounter","modelPersonalities","style","avgLength","technical","mockResponses","contextualResponses","delay","ms","Promise","resolve","setTimeout","getRandomFromArray","array","Math","floor","random","length","getContextualResponse","message","aiConfig","arguments","undefined","lowerMessage","toLowerCase","baseResponse","includes","applyAIConfigToResponse","response","config","model","temperature","personalityPreset","systemPrompt","modelProps","substring","replace","split","createMessage","text","conversationId","id","isBot","timestamp","Date","toISOString","mockApiService","async","checkHealth","success","data","status","getConversations","Array","from","entries","map","_ref","conv","title","lastMessage","messages","messageCount","createdAt","updatedAt","sort","a","b","createConversation","now","toString","substr","conversation","set","getConversation","get","Error","sendMessage","trim","userMessage","push","filter","m","aiMessage","streamingEnabled","fullResponse","isStreaming","processingTime","aiResponseText","deleteConversation","delete","clearAllConversations","clear"],"sourceRoot":""}